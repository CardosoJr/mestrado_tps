{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vv3nWx11Y7-y",
        "outputId": "cea2a067-bd47-4dfe-c96f-f98cead1afbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tue Feb  8 12:51:53 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxikYinjYyx8",
        "outputId": "c573d9f9-c65a-4afe-8143-72c618386657"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: torch 1.10.0+cu111\n",
            "Uninstalling torch-1.10.0+cu111:\n",
            "  Would remove:\n",
            "    /usr/local/bin/convert-caffe2-to-onnx\n",
            "    /usr/local/bin/convert-onnx-to-caffe2\n",
            "    /usr/local/bin/torchrun\n",
            "    /usr/local/lib/python3.7/dist-packages/caffe2/*\n",
            "    /usr/local/lib/python3.7/dist-packages/torch-1.10.0+cu111.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled torch-1.10.0+cu111\n",
            "Found existing installation: torchvision 0.11.1+cu111\n",
            "Uninstalling torchvision-0.11.1+cu111:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.7/dist-packages/torchvision-0.11.1+cu111.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/torchvision.libs/libcudart.7be20469.so.11.0\n",
            "    /usr/local/lib/python3.7/dist-packages/torchvision.libs/libjpeg.ceea7512.so.62\n",
            "    /usr/local/lib/python3.7/dist-packages/torchvision.libs/libnvjpeg.8313e8da.so.11\n",
            "    /usr/local/lib/python3.7/dist-packages/torchvision.libs/libpng16.7f72a3c5.so.16\n",
            "    /usr/local/lib/python3.7/dist-packages/torchvision.libs/libz.1328edc3.so.1\n",
            "    /usr/local/lib/python3.7/dist-packages/torchvision/*\n",
            "Proceed (y/n)?   Successfully uninstalled torchvision-0.11.1+cu111\n"
          ]
        }
      ],
      "source": [
        "!yes y | pip uninstall torchy torchvision\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pY-_swgyY4V5",
        "outputId": "bcb5887b-a92b-46bb-dc16-7825f2c5e685"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.9.0+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torch-1.9.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (2041.3 MB)\n",
            "\u001b[K     |█████████████                   | 834.1 MB 1.3 MB/s eta 0:15:27tcmalloc: large alloc 1147494400 bytes == 0x55a058c50000 @  0x7f94aff8d615 0x55a01f3a53bc 0x55a01f48618a 0x55a01f3a81cd 0x55a01f49ab3d 0x55a01f41c458 0x55a01f41702f 0x55a01f3a9aba 0x55a01f41c2c0 0x55a01f41702f 0x55a01f3a9aba 0x55a01f418cd4 0x55a01f49b986 0x55a01f418350 0x55a01f49b986 0x55a01f418350 0x55a01f49b986 0x55a01f418350 0x55a01f3a9f19 0x55a01f3eda79 0x55a01f3a8b32 0x55a01f41c1dd 0x55a01f41702f 0x55a01f3a9aba 0x55a01f418cd4 0x55a01f41702f 0x55a01f3a9aba 0x55a01f417eae 0x55a01f3a99da 0x55a01f418108 0x55a01f41702f\n",
            "\u001b[K     |████████████████▌               | 1055.7 MB 1.4 MB/s eta 0:12:02tcmalloc: large alloc 1434370048 bytes == 0x55a09d2a6000 @  0x7f94aff8d615 0x55a01f3a53bc 0x55a01f48618a 0x55a01f3a81cd 0x55a01f49ab3d 0x55a01f41c458 0x55a01f41702f 0x55a01f3a9aba 0x55a01f41c2c0 0x55a01f41702f 0x55a01f3a9aba 0x55a01f418cd4 0x55a01f49b986 0x55a01f418350 0x55a01f49b986 0x55a01f418350 0x55a01f49b986 0x55a01f418350 0x55a01f3a9f19 0x55a01f3eda79 0x55a01f3a8b32 0x55a01f41c1dd 0x55a01f41702f 0x55a01f3a9aba 0x55a01f418cd4 0x55a01f41702f 0x55a01f3a9aba 0x55a01f417eae 0x55a01f3a99da 0x55a01f418108 0x55a01f41702f\n",
            "\u001b[K     |█████████████████████           | 1336.2 MB 1.2 MB/s eta 0:09:44tcmalloc: large alloc 1792966656 bytes == 0x55a0220d8000 @  0x7f94aff8d615 0x55a01f3a53bc 0x55a01f48618a 0x55a01f3a81cd 0x55a01f49ab3d 0x55a01f41c458 0x55a01f41702f 0x55a01f3a9aba 0x55a01f41c2c0 0x55a01f41702f 0x55a01f3a9aba 0x55a01f418cd4 0x55a01f49b986 0x55a01f418350 0x55a01f49b986 0x55a01f418350 0x55a01f49b986 0x55a01f418350 0x55a01f3a9f19 0x55a01f3eda79 0x55a01f3a8b32 0x55a01f41c1dd 0x55a01f41702f 0x55a01f3a9aba 0x55a01f418cd4 0x55a01f41702f 0x55a01f3a9aba 0x55a01f417eae 0x55a01f3a99da 0x55a01f418108 0x55a01f41702f\n",
            "\u001b[K     |██████████████████████████▌     | 1691.1 MB 1.4 MB/s eta 0:04:03tcmalloc: large alloc 2241208320 bytes == 0x55a08cec0000 @  0x7f94aff8d615 0x55a01f3a53bc 0x55a01f48618a 0x55a01f3a81cd 0x55a01f49ab3d 0x55a01f41c458 0x55a01f41702f 0x55a01f3a9aba 0x55a01f41c2c0 0x55a01f41702f 0x55a01f3a9aba 0x55a01f418cd4 0x55a01f49b986 0x55a01f418350 0x55a01f49b986 0x55a01f418350 0x55a01f49b986 0x55a01f418350 0x55a01f3a9f19 0x55a01f3eda79 0x55a01f3a8b32 0x55a01f41c1dd 0x55a01f41702f 0x55a01f3a9aba 0x55a01f418cd4 0x55a01f41702f 0x55a01f3a9aba 0x55a01f417eae 0x55a01f3a99da 0x55a01f418108 0x55a01f41702f\n",
            "\u001b[K     |████████████████████████████████| 2041.3 MB 308 kB/s eta 0:00:01tcmalloc: large alloc 2041348096 bytes == 0x55a112822000 @  0x7f94aff8c1e7 0x55a01f3db5d7 0x55a01f3a53bc 0x55a01f48618a 0x55a01f3a81cd 0x55a01f49ab3d 0x55a01f41c458 0x55a01f41702f 0x55a01f3a9aba 0x55a01f418108 0x55a01f41702f 0x55a01f3a9aba 0x55a01f418108 0x55a01f41702f 0x55a01f3a9aba 0x55a01f418108 0x55a01f41702f 0x55a01f3a9aba 0x55a01f418108 0x55a01f41702f 0x55a01f3a9aba 0x55a01f418108 0x55a01f3a99da 0x55a01f418108 0x55a01f41702f 0x55a01f3a9aba 0x55a01f418cd4 0x55a01f41702f 0x55a01f3a9aba 0x55a01f418cd4 0x55a01f41702f\n",
            "tcmalloc: large alloc 2551685120 bytes == 0x55a20076e000 @  0x7f94aff8d615 0x55a01f3a53bc 0x55a01f48618a 0x55a01f3a81cd 0x55a01f49ab3d 0x55a01f41c458 0x55a01f41702f 0x55a01f3a9aba 0x55a01f418108 0x55a01f41702f 0x55a01f3a9aba 0x55a01f418108 0x55a01f41702f 0x55a01f3a9aba 0x55a01f418108 0x55a01f41702f 0x55a01f3a9aba 0x55a01f418108 0x55a01f41702f 0x55a01f3a9aba 0x55a01f418108 0x55a01f3a99da 0x55a01f418108 0x55a01f41702f 0x55a01f3a9aba 0x55a01f418cd4 0x55a01f41702f 0x55a01f3a9aba 0x55a01f418cd4 0x55a01f41702f 0x55a01f3aa151\n",
            "\u001b[K     |████████████████████████████████| 2041.3 MB 7.1 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.10.0+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.10.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (23.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 23.2 MB 1.4 MB/s \n",
            "\u001b[?25hCollecting torchaudio==0.9.0\n",
            "  Downloading torchaudio-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0+cu111) (3.10.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0+cu111) (1.19.5)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0+cu111) (7.1.2)\n",
            "Installing collected packages: torch, torchvision, torchaudio\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 0.10.0+cu111\n",
            "    Uninstalling torchaudio-0.10.0+cu111:\n",
            "      Successfully uninstalled torchaudio-0.10.0+cu111\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.9.0+cu111 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.9.0+cu111 torchaudio-0.9.0 torchvision-0.10.0+cu111\n"
          ]
        }
      ],
      "source": [
        "!yes y | pip install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2KEh_XKaZ5Ui"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "import numpy as np\n",
        "from margin_loss_pt import LargeMarginLoss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gj0FINNPbE81",
        "outputId": "931ca146-fd21-4381-ffed-f95f3deb7010"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.9.0+cu111\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(torch.__version__)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "OWsDc5u8WH1N"
      },
      "outputs": [],
      "source": [
        "def test(model, test_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    with torch.no_grad(): \n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output, *_ = model(data)\n",
        "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
        "            _, idx = output.max(dim=1)\n",
        "            correct += (idx == target).sum().item()\n",
        "\n",
        "    print('Test set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nehoLAigWH1P",
        "outputId": "9c8685dd-e30d-477c-b3c2-5fea5994a6a8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
          ]
        }
      ],
      "source": [
        "from torch.utils import data\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "\n",
        "train_loader = data.DataLoader(\n",
        "        datasets.MNIST('./data', train=True, download=True,\n",
        "                       transform=transforms.Compose([\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Normalize((0.1307,), (0.3081,))\n",
        "                       ])),\n",
        "        batch_size=256, shuffle=True, drop_last=True)\n",
        "\n",
        "test_loader = data.DataLoader(\n",
        "        datasets.MNIST('./data', train=False,\n",
        "                       transform=transforms.Compose([\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Normalize((0.1307,), (0.3081,))\n",
        "                       ])),\n",
        "        batch_size=2048, shuffle=False, drop_last=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "coN085YhWH1P"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, 5, 1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(True),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, 5, 1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(True),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        \n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(True)\n",
        "        )\n",
        "        self.fc2 = nn.Linear(512, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        conv1 = self.conv1(x)\n",
        "        conv2 = self.conv2(conv1)\n",
        "        flatten = conv2.view(x.shape[0], -1)        \n",
        "        fc1 = self.fc1(flatten)\n",
        "        fc2 = self.fc2(fc1)\n",
        "        return fc2, [conv1, conv2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prRJhSvpWH1P",
        "outputId": "49e4f462-9ed8-4a5c-c110-84da945e9b6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: -3864.983398\n",
            "Train Epoch: 0 [25600/60000 (43%)]\tLoss: -4168.206055\n",
            "Train Epoch: 0 [51200/60000 (85%)]\tLoss: -4269.446289\n",
            "Test set: Accuracy: 8887/10000 (89%)\n",
            "\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: -4106.529297\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: -4173.661133\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: -4211.122070\n",
            "Test set: Accuracy: 8896/10000 (89%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: -4267.726074\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: -4721.286133\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: -4668.863281\n",
            "Test set: Accuracy: 9898/10000 (99%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: -4893.762207\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: -4816.452148\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: -4853.994141\n",
            "Test set: Accuracy: 9904/10000 (99%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: -4753.899414\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: -4865.370117\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: -4841.532715\n",
            "Test set: Accuracy: 9909/10000 (99%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "lm = LargeMarginLoss(\n",
        "    gamma=10000,\n",
        "    alpha_factor=4,\n",
        "    top_k=1,\n",
        "    dist_norm=np.inf\n",
        ")\n",
        "\n",
        "def train_lm(model, train_loader, optimizer, epoch, lm):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data = data.to(device)\n",
        "        one_hot = torch.zeros(len(target), 10).scatter_(1, target.unsqueeze(1), 1.).float()\n",
        "        one_hot = one_hot.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        output, feature_maps = model(data)\n",
        "        #loss = F.mse_loss(output, target) * 5e-4 # l2_loss_weght\n",
        "        loss = lm(output, one_hot, feature_maps)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 100 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "# net = Net().to(device)\n",
        "net = nn.DataParallel(net).to(device)\n",
        "optim = Adam(net.parameters())\n",
        "for i in range(0, 5):\n",
        "    train_lm(net, train_loader, optim, i, lm)\n",
        "    test(net, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kB73mFtgWH1R",
        "outputId": "e2200ce4-60fd-4c82-9e51-8a72ea67a5ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.312209\n",
            "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 0.057380\n",
            "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.069225\n",
            "Test set: Accuracy: 9871/10000 (99%)\n",
            "\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.021330\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.058321\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.032983\n",
            "Test set: Accuracy: 9887/10000 (99%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.020935\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.051123\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.020498\n",
            "Test set: Accuracy: 9911/10000 (99%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.018395\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.030107\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.018094\n",
            "Test set: Accuracy: 9903/10000 (99%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.016279\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.013521\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.013503\n",
            "Test set: Accuracy: 9915/10000 (99%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def train_ce(model, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output, _ = model(data)\n",
        "        loss = F.cross_entropy(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 100 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "net = Net().to(device)\n",
        "# net = nn.DataParallel(net).to(device)\n",
        "optim = Adam(net.parameters())\n",
        "for i in range(0, 5):    \n",
        "    train_ce(net, train_loader, optim, i)\n",
        "    test(net, test_loader)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "mnist_pt.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
